{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyOzJ9rzwBDU8FfAkvxaALyw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DutchVandaline/Artificial_Intelligence/blob/main/GPT2_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building GPT2 from scratch.\n",
        "\n",
        "Building GPT2 is a complex task but I guess I can learn about transformers. For now on, I don't really understand about `attention` and no basics with `RNN`, `LSTM`. It might be a challenging task to understand the transformers of course. But, I have built ViT (Vision Transformer). Why don't I give it a shot?\n",
        "\n",
        "* References\n",
        "\n",
        "  * Illustrated-gpt2 by jay alammar : https://jalammar.github.io/illustrated-gpt2/#part-1-got-and-language-modeling\n",
        "  \n",
        "  * Here's how you can build and train GPT-2 : https://dev.to/amit_kharel_aae65abe2b111/heres-how-you-can-build-and-train-gpt-2-from-scratch-using-pytorch-345n\n",
        "\n",
        "I've used jay alammar's blog post to understand the architecture and how gpt2 works and bottom blog post is for dataset and preprocessing."
      ],
      "metadata": {
        "id": "EXVUeWL5qhuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "from torch import nn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "print(f\"torch version: {torch.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duvZEIXwqcwG",
        "outputId": "e13b848e-a54e-4071-e2ed-0580185eb433"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.4.0+cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iDibO7StrwZL",
        "outputId": "956466a1-ea0b-45a3-ba24-d89ece848ca7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building Character based Encoder and Decoder"
      ],
      "metadata": {
        "id": "5y7GdSAktdU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"data.txt\"\n",
        "text = open(data_dir, 'r').read()\n",
        "\n",
        "chars = list(set(text))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "print(f\"We have total {vocab_size} vocabularies and they are\\n {''.join(chars)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ka3WgdGr5r9",
        "outputId": "1c02cec2-f0d4-4873-8934-e2fe7ef3792b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have total 89 vocabularies and they are\n",
            " 9!Xj0;R2W)1KóïOrkpT\n",
            "oíMéP”—'“LEctx4\"hD5bJf8imy.I/?6(e:nzlq,s[adZ&w3B*\\VHU] GuASF7N-Y’vgCQ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chr_to_idx = {c:i for i, c in enumerate(chars)}\n",
        "idx_to_chr = {i:c for i, c in enumerate(chars)}\n",
        "\n",
        "def encode(input_text: str) -> list[int]:\n",
        "    return [chr_to_idx[t] for t in input_text]\n",
        "\n",
        "def decode(input_tokens: list[int]) -> str:\n",
        "    return \"\".join([idx_to_chr[i] for i in input_tokens])\n",
        "\n",
        "encoded_word = encode(\"Hello World\")\n",
        "print(f\"Hello World -> {encoded_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2-QQTC_tHw4",
        "outputId": "25eb471f-ef31-4c8d-cbdc-9b6b01387d56"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World -> [71, 52, 56, 56, 20, 74, 8, 20, 15, 56, 62]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.long, device=device)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OG8AltJPtTuc",
        "outputId": "c66be559-7108-48fc-8e78-9b178b529884"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([71, 52, 74,  ..., 56, 52, 35])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}