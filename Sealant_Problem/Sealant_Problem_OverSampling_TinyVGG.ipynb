{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-07T04:54:39.469703500Z",
          "start_time": "2024-11-07T04:54:39.455702600Z"
        },
        "collapsed": true,
        "id": "initial_id",
        "outputId": "20b70128-7753-4279-c1da-f5002c0fdef6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version : 2.5.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "print(f\"torch version : {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aic36uwFp17Z",
        "outputId": "da3e06d5-8d40-438f-d5d5-74d93fb127cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "aic36uwFp17Z",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b389ff70c6dca387",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-07T04:54:39.849703500Z",
          "start_time": "2024-11-07T04:54:39.830703Z"
        },
        "id": "b389ff70c6dca387",
        "outputId": "89826ce6-9f4a-41d5-a277-38a6ce4aad7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a76e6fa4e5d641c5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-07T04:54:39.867703800Z",
          "start_time": "2024-11-07T04:54:39.844703800Z"
        },
        "id": "a76e6fa4e5d641c5"
      },
      "outputs": [],
      "source": [
        "image_path = \"/content/drive/MyDrive/oversampling_data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d3473c4b8e0f4a42",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-07T04:54:39.877702300Z",
          "start_time": "2024-11-07T04:54:39.863704Z"
        },
        "id": "d3473c4b8e0f4a42",
        "outputId": "da8bc801-8f8d-4f45-aa6d-8c2c05aa5f1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\n",
            "Cloning into 'Artificial_Intelligence'...\n",
            "remote: Enumerating objects: 371, done.\u001b[K\n",
            "remote: Counting objects: 100% (307/307), done.\u001b[K\n",
            "remote: Compressing objects: 100% (227/227), done.\u001b[K\n",
            "remote: Total 371 (delta 136), reused 200 (delta 70), pack-reused 64 (from 1)\u001b[K\n",
            "Receiving objects: 100% (371/371), 41.71 MiB | 14.31 MiB/s, done.\n",
            "Resolving deltas: 100% (152/152), done.\n"
          ]
        }
      ],
      "source": [
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from pytorch_modules.pytorch_modules import data_setup, engine\n",
        "    from helper_functions import download_data, set_seeds, plot_loss_curves\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/DutchVandaline/Artificial_Intelligence.git\n",
        "    !mv Artificial_Intelligence/pytorch_modules .\n",
        "    !mv Artificial_Intelligence/helper_functions.py . # get the helper_functions.py script\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from pytorch_modules.pytorch_modules import data_setup, engine\n",
        "    from helper_functions import download_data, set_seeds, plot_loss_curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "83743f75c14bb4f1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-07T04:54:40.010703300Z",
          "start_time": "2024-11-07T04:54:39.990703800Z"
        },
        "id": "83743f75c14bb4f1",
        "outputId": "a2015d5f-847f-497e-81a2-e20cca6d1d30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3 directoreis and 0 images in '/content/drive/MyDrive/oversampling_data'.\n",
            "There are 2 directoreis and 0 images in '/content/drive/MyDrive/oversampling_data/test'.\n",
            "There are 0 directoreis and 353 images in '/content/drive/MyDrive/oversampling_data/test/normal'.\n",
            "There are 0 directoreis and 393 images in '/content/drive/MyDrive/oversampling_data/test/defect'.\n",
            "There are 2 directoreis and 0 images in '/content/drive/MyDrive/oversampling_data/z_keep_out_for_final_test'.\n",
            "There are 0 directoreis and 20 images in '/content/drive/MyDrive/oversampling_data/z_keep_out_for_final_test/defect'.\n",
            "There are 0 directoreis and 20 images in '/content/drive/MyDrive/oversampling_data/z_keep_out_for_final_test/normal'.\n",
            "There are 2 directoreis and 0 images in '/content/drive/MyDrive/oversampling_data/train'.\n",
            "There are 0 directoreis and 1409 images in '/content/drive/MyDrive/oversampling_data/train/normal'.\n",
            "There are 0 directoreis and 1569 images in '/content/drive/MyDrive/oversampling_data/train/defect'.\n"
          ]
        }
      ],
      "source": [
        "# Count Image Data length\n",
        "import os\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\" Walks through dir_path returning its conents.\"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directoreis and {len(filenames)} images in '{dirpath}'.\")\n",
        "walk_through_dir(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "29a37bfbfca298ab",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-07T04:54:40.566085300Z",
          "start_time": "2024-11-07T04:54:40.558085100Z"
        },
        "id": "29a37bfbfca298ab"
      },
      "outputs": [],
      "source": [
        "oversampling_train_dir = \"/content/drive/MyDrive/oversampling_data/train\"\n",
        "oversampling_test_dir = \"/content/drive/MyDrive/oversampling_data/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "df7f10c39bc60fae",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-07T04:54:40.866561300Z",
          "start_time": "2024-11-07T04:54:40.847561600Z"
        },
        "id": "df7f10c39bc60fae",
        "outputId": "558ab3b5-575e-471c-f553-f41922ca8321",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compose(\n",
              "    Resize(size=(2532, 824), interpolation=bilinear, max_size=None, antialias=True)\n",
              "    ToTensor()\n",
              "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Get the transforms used to create our pretrained weights\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((2532, 824)), # normal은 2532임 defect는 2732\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "manual_transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7eb10268ae87ee6d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-07T04:54:41.166944600Z",
          "start_time": "2024-11-07T04:54:41.140943400Z"
        },
        "id": "7eb10268ae87ee6d",
        "outputId": "f19bed56-31cf-47e9-ae8d-3819ca910549",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#Set up dataloaders\n",
        "from pytorch_modules.pytorch_modules import data_setup\n",
        "oversampling_train_dataloader, oversampling_test_dataloader, class_names = data_setup.create_dataloaders(train_dir=oversampling_train_dir,\n",
        "                                                                                                     test_dir=oversampling_test_dir,\n",
        "                                                                                                     transform=manual_transforms,\n",
        "                                                                                                    num_workers=0,\n",
        "                                                                                                     batch_size=16)\n",
        "len(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a9a44ecd6055b213",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-07T04:54:41.680734700Z",
          "start_time": "2024-11-07T04:54:41.665736Z"
        },
        "id": "a9a44ecd6055b213"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "  \"\"\"\n",
        "  Model architecture copying TinyVGG from CNN explainer\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "                input_shape:int,\n",
        "                hidden_units:int,\n",
        "                output_shape = int) -> None:\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                      stride = 2)\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                      stride = 2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units * 127890,\n",
        "                  out_features = output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    #print(x.shape)\n",
        "    x=self.conv_block_2(x)\n",
        "    #print(x.shape)\n",
        "    x = self.classifier(x)\n",
        "    #print(x.shape)\n",
        "    return x\n",
        "      #return self.classifier(self.conv_block2(self.conv_block_1(x))) # benefits from opterator fusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6d1c8c559cab7811",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-07T04:54:42.280266800Z",
          "start_time": "2024-11-07T04:54:42.250267500Z"
        },
        "id": "6d1c8c559cab7811",
        "outputId": "fbc01370-306e-4fd4-de1f-691c0f35ab59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyVGG(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=1278900, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "tinyVGG = TinyVGG(input_shape=3, hidden_units=10, output_shape=len(class_names)).to(device)\n",
        "tinyVGG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c33baddaffe6a330",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-07T04:54:42.780188400Z",
          "start_time": "2024-11-07T04:54:42.773188400Z"
        },
        "id": "c33baddaffe6a330"
      },
      "outputs": [],
      "source": [
        "# Define loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(tinyVGG.parameters(), lr= 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ec8c4514d623d7f1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-07T04:54:43.350305100Z",
          "start_time": "2024-11-07T04:54:43.339305100Z"
        },
        "id": "ec8c4514d623d7f1",
        "outputId": "f4fa3df2-5af2-4a9b-fae4-6a3acd3b86e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "84c04f5b11b7a345",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-07T05:24:45.540561900Z",
          "start_time": "2024-11-07T04:54:43.605350100Z"
        },
        "id": "84c04f5b11b7a345",
        "outputId": "80638d3f-6cba-4c3a-e35e-18b6bb5f1ca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251,
          "referenced_widgets": [
            "494afae38f424f5788ffe7d63e74fffe",
            "8de722fb097c4f52bdabcd3ce2123379",
            "f58be19658084b3aac2f46ce3ded776f",
            "b210805a855e494bac94e6a56c0aa9c4",
            "eff49d304222463fa3c41eba12b9492e",
            "81101e20bbd84e6eab77d914c30a6004",
            "e8b1c1481b994593ae32b0431a779264",
            "104cad7b6e3c41958be174b6c682821c",
            "83117eb644484415bfc4e0d017bf4a8a",
            "b977b2386a0b4c99b664b3cf48e6d392",
            "a69fe3e3caa64d37b8256ec2460afcca"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "494afae38f424f5788ffe7d63e74fffe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.1344 | train_acc: 0.9756 | test_loss: 0.0001 | test_acc: 1.0000\n",
            "Epoch: 2 | train_loss: 0.0000 | train_acc: 1.0000 | test_loss: 0.0000 | test_acc: 1.0000\n",
            "Epoch: 3 | train_loss: 0.0000 | train_acc: 1.0000 | test_loss: 0.0000 | test_acc: 1.0000\n",
            "Epoch: 4 | train_loss: 0.0000 | train_acc: 1.0000 | test_loss: 0.0000 | test_acc: 1.0000\n",
            "Epoch: 5 | train_loss: 0.0000 | train_acc: 1.0000 | test_loss: 0.0000 | test_acc: 1.0000\n",
            "Epoch: 6 | train_loss: 0.0000 | train_acc: 1.0000 | test_loss: 0.0000 | test_acc: 1.0000\n",
            "Epoch: 7 | train_loss: 0.0000 | train_acc: 1.0000 | test_loss: 0.0000 | test_acc: 1.0000\n",
            "Epoch: 8 | train_loss: 0.0000 | train_acc: 1.0000 | test_loss: 0.0000 | test_acc: 1.0000\n",
            "Epoch: 9 | train_loss: 0.0000 | train_acc: 1.0000 | test_loss: 0.0000 | test_acc: 1.0000\n",
            "Epoch: 10 | train_loss: 0.0000 | train_acc: 1.0000 | test_loss: 0.0000 | test_acc: 1.0000\n",
            "[INFO] Total training time:  6196.943 seconds\n"
          ]
        }
      ],
      "source": [
        "from pytorch_modules.pytorch_modules import engine\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "results = engine.train(model=tinyVGG,\n",
        "                       train_dataloader=oversampling_train_dataloader,\n",
        "                       test_dataloader =oversampling_test_dataloader,\n",
        "                       optimizer=optimizer,\n",
        "                       loss_fn=loss_fn,\n",
        "                       epochs=10,\n",
        "                       device=device)\n",
        "\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time-start_time: .3f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b76d1837b7be3b9a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-07T05:24:45.691685500Z",
          "start_time": "2024-11-07T05:24:45.542560900Z"
        },
        "id": "b76d1837b7be3b9a",
        "outputId": "380e0082-9049-43a5-b8ae-f844c1006356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/C:/junha/Personal_Notebook/oversampling_data/z_keep_out_for_final_test/normal/20240823_101759.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-08368ad7abae>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"C:/junha/Personal_Notebook/oversampling_data/z_keep_out_for_final_test/normal/20240823_101759.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m pred_and_plot_image(model=tinyVGG,\n\u001b[0m\u001b[1;32m      5\u001b[0m                            \u001b[0mimage_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                            \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pytorch_modules/pytorch_modules/predictions.py\u001b[0m in \u001b[0;36mpred_and_plot_image\u001b[0;34m(model, class_names, image_path, image_size, transform, device)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Open image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Create transformation for image (if one doesn't exist)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3468\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3469\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3470\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3471\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/C:/junha/Personal_Notebook/oversampling_data/z_keep_out_for_final_test/normal/20240823_101759.jpg'"
          ]
        }
      ],
      "source": [
        "from pytorch_modules.pytorch_modules.predictions import pred_and_plot_image\n",
        "input_image = \"/content/drive/MyDrive/oversampling_data/z_keep_out_for_final_test/normal/20240823_101759.jpg\"\n",
        "\n",
        "pred_and_plot_image(model=tinyVGG,\n",
        "                           image_path=input_image,\n",
        "                           class_names=class_names,\n",
        "                            transform=manual_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44c53cf20692262c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-07T05:25:18.050006600Z",
          "start_time": "2024-11-07T05:24:45.691685500Z"
        },
        "id": "44c53cf20692262c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import numpy as np\n",
        "\n",
        "# Ensure the model is in evaluation mode\n",
        "tinyVGG.eval()\n",
        "\n",
        "# Create lists to store true and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Move model to the appropriate device (e.g., CPU or GPU)\n",
        "tinyVGG.to(device)\n",
        "\n",
        "# Disable gradient calculation for evaluation\n",
        "with torch.no_grad():\n",
        "    for data in oversampling_test_dataloader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = tinyVGG(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        # Collect predictions and true labels\n",
        "        predicted_labels.extend(preds.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a97d8581670a438",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-07T05:25:51.323914700Z",
          "start_time": "2024-11-07T05:25:18.054600600Z"
        },
        "id": "2a97d8581670a438"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score, roc_curve, auc\n",
        "import numpy as np\n",
        "\n",
        "# Ensure the model is in evaluation mode and move it to the appropriate device\n",
        "tinyVGG.to(device)\n",
        "tinyVGG.eval()\n",
        "\n",
        "# Create lists to store true and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "all_probabilities = []\n",
        "\n",
        "# Disable gradient calculation for evaluation\n",
        "with torch.no_grad():\n",
        "    for data in oversampling_test_dataloader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = tinyVGG(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        # Collect predictions, true labels, and predicted probabilities\n",
        "        predicted_labels.extend(preds.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "        all_probabilities.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n",
        "\n",
        "# Calculate F1 score (micro and macro)\n",
        "f1_micro = f1_score(true_labels, predicted_labels, average='micro')\n",
        "f1_macro = f1_score(true_labels, predicted_labels, average='macro')\n",
        "print(f\"F1 Score (Micro): {f1_micro}\")\n",
        "print(f\"F1 Score (Macro): {f1_macro}\")\n",
        "\n",
        "# Check if the task is binary classification\n",
        "if len(np.unique(true_labels)) == 2:\n",
        "    # Binary classification: Use only one ROC curve\n",
        "    probabilities_class_1 = np.array(all_probabilities)[:, 1]\n",
        "    fpr, tpr, thresholds = roc_curve(true_labels, probabilities_class_1)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # Plot ROC curve for binary classification\n",
        "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "\n",
        "# Print total count of true and predicted labels for debugging\n",
        "print(f\"Total true labels collected: {len(true_labels)}\")\n",
        "print(f\"Total predicted labels collected: {len(predicted_labels)}\")\n",
        "print(f\"True Labels: {true_labels}\")\n",
        "print(f\"Predicted Labels: {predicted_labels}\")\n",
        "\n",
        "\n",
        "# Plot settings\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)  # Random guess line\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5f89b3bb8b3368d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-07T05:25:56.912933300Z",
          "start_time": "2024-11-07T05:25:56.885933600Z"
        },
        "id": "d5f89b3bb8b3368d"
      },
      "outputs": [],
      "source": [
        "from pytorch_modules.pytorch_modules import utils\n",
        "\n",
        "utils.save_model(model=tinyVGG,\n",
        "                 target_dir=\"/content/drive/MyDrive/models\",\n",
        "                 model_name=\"tinyVGG_OverSampling.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = tinyVGG()\n",
        "loaded_model.load_state_dict(torch.load(\"/content/drive/MyDrive/models/tinyVGG_OverSampling.pth\"))"
      ],
      "metadata": {
        "id": "BtmPTKZupbnw"
      },
      "id": "BtmPTKZupbnw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5b55f42e701ac50",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-07T03:14:30.342425400Z",
          "start_time": "2024-11-07T03:14:27.606293600Z"
        },
        "id": "a5b55f42e701ac50"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from pytorch_modules.pytorch_modules.predictions import pred_and_plot_image\n",
        "\n",
        "# Define paths to normal and defect images\n",
        "normal_folder = \"/content/drive/MyDrive/oversampling_data/z_keep_out_for_final_test/normal\"\n",
        "defect_folder = \"/content/drive/MyDrive/oversampling_data/z_keep_out_for_final_test/defect\"\n",
        "\n",
        "# List all images in normal and defect folders with labels\n",
        "normal_images = [(os.path.join(normal_folder, img), \"normal\") for img in os.listdir(normal_folder)]\n",
        "defect_images = [(os.path.join(defect_folder, img), \"defect\") for img in os.listdir(defect_folder)]\n",
        "\n",
        "# Combine and shuffle the images\n",
        "all_images = normal_images + defect_images\n",
        "random.shuffle(all_images)\n",
        "\n",
        "# Initialize list to store predictions\n",
        "results = []\n",
        "\n",
        "# Iterate over each image, predict, and store the results\n",
        "for image_path, true_label in all_images:\n",
        "    # Predict the label using the model\n",
        "    pred_and_plot_image(model=loaded_model, image_path=image_path, class_names=class_names, transform=manual_transforms)\n",
        "\n",
        "    # Extract the prediction label and probability from the plot title\n",
        "    plt_title = plt.gca().get_title()  # Get title containing label and probability\n",
        "    pred_label = plt_title.split('|')[0].split(': ')[1].strip()\n",
        "    pred_prob = plt_title.split('|')[1].split(': ')[1].strip()  # No conversion, keep the original\n",
        "\n",
        "    # Append results including true label\n",
        "    results.append([os.path.basename(image_path), true_label, pred_label, pred_prob])\n",
        "\n",
        "    # Close the plot to manage resources\n",
        "    plt.close()\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results, columns=[\"Image\", \"True Label\", \"Prediction Label\", \"Prediction Probability\"])\n",
        "\n",
        "# Display results in a table\n",
        "fig, ax = plt.subplots(figsize=(10, len(results)*0.5))  # Adjust height based on number of rows\n",
        "ax.axis('off')  # Turn off the axis\n",
        "table = ax.table(cellText=results_df.values, colLabels=results_df.columns, cellLoc='center', loc='center')\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(10)\n",
        "table.auto_set_column_width(col=list(range(len(results_df.columns))))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fbd6829e57e6b70",
      "metadata": {
        "id": "9fbd6829e57e6b70"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "494afae38f424f5788ffe7d63e74fffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8de722fb097c4f52bdabcd3ce2123379",
              "IPY_MODEL_f58be19658084b3aac2f46ce3ded776f",
              "IPY_MODEL_b210805a855e494bac94e6a56c0aa9c4"
            ],
            "layout": "IPY_MODEL_eff49d304222463fa3c41eba12b9492e"
          }
        },
        "8de722fb097c4f52bdabcd3ce2123379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81101e20bbd84e6eab77d914c30a6004",
            "placeholder": "​",
            "style": "IPY_MODEL_e8b1c1481b994593ae32b0431a779264",
            "value": "100%"
          }
        },
        "f58be19658084b3aac2f46ce3ded776f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_104cad7b6e3c41958be174b6c682821c",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83117eb644484415bfc4e0d017bf4a8a",
            "value": 10
          }
        },
        "b210805a855e494bac94e6a56c0aa9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b977b2386a0b4c99b664b3cf48e6d392",
            "placeholder": "​",
            "style": "IPY_MODEL_a69fe3e3caa64d37b8256ec2460afcca",
            "value": " 10/10 [1:43:16&lt;00:00, 478.14s/it]"
          }
        },
        "eff49d304222463fa3c41eba12b9492e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81101e20bbd84e6eab77d914c30a6004": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b1c1481b994593ae32b0431a779264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "104cad7b6e3c41958be174b6c682821c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83117eb644484415bfc4e0d017bf4a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b977b2386a0b4c99b664b3cf48e6d392": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a69fe3e3caa64d37b8256ec2460afcca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}