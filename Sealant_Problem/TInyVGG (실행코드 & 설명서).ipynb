{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TinyVGG 파일형식\n",
    "- model.eval 을 진행하기 위해선 다음과 같은 파일 형식을 만들어야 합니다. 해당 구조를 만들기 위한 코드는 검증용 이미지 폴더 전처리용 코드 move_images_based_on_defect 코드에 있습니다. 코드를 따라 진행하시면 됩니다. (클릭하시면 디렉토리가 제대로 표시됩니다.)\n",
    "|-- data\n",
    "    |-- val\n",
    "        |-- normal\n",
    "            |-- 20240806_170349.png\n",
    "            |-- 20240806_170404.png ...\n",
    "        |-- defect\n",
    "            |-- 20240806_170360.png\n",
    "            |-- 20240806_170467.png ..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7edc5ae6c287dbe1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "829fe03369f66d26"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 검증용 이미지 폴더 전처리용 코드 \n",
    "### img_directory에 검증용 이미지 폴더(jpg 형식) 경로를 입력하신 후, txt_directory에는 검증용 이미지 라벨(txt 형식) 경로를 입력해 주십시오. 라벨에 따라서 오류와 정상 이미지를 각각의 폴더로 분류할 것입니다. 제공된 데이터 형식에 따라, 라벨 txt데이터에 아무것도 적혀있지 않은 데이터를 정상 데이터로 분류합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c7e933b4f5f5e78"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "img_directory = 'printing/images' # TODO: 검증용 이미지 디렉토리 경로를 입력해 주십시오.\n",
    "txt_directory = 'printing/labels' # TODO: 검증용 이미지 라벨 디렉토리 경로를 입력해 주심시오.\n",
    "normal_directory = 'val/normal' # 검증용 정상 이미지 저장 경로\n",
    "defect_directory = 'val/defect' # 검증용 비정상 이미지 저장 경로\n",
    "\n",
    "def move_images_based_on_defect(img_dir, txt_dir, normal_dir, defect_dir):\n",
    "    os.makedirs(normal_dir, exist_ok=True)\n",
    "    os.makedirs(defect_dir, exist_ok=True)\n",
    "\n",
    "    for img_file in os.listdir(img_dir):\n",
    "        if img_file.endswith('.jpg'):\n",
    "            img_path = os.path.join(img_dir, img_file)\n",
    "            txt_path = os.path.join(txt_dir, img_file.replace('.jpg', '.txt'))\n",
    "\n",
    "            with open(txt_path, 'r') as f:\n",
    "                text_content = f.read().strip()\n",
    "\n",
    "            if text_content == \"\":\n",
    "                shutil.move(img_path, os.path.join(normal_dir, img_file))\n",
    "                print(f\"Moved {img_file} to {normal_dir}\")\n",
    "            else:\n",
    "                shutil.move(img_path, os.path.join(defect_dir, img_file))\n",
    "                print(f\"Moved {img_file} to {defect_dir}\")\n",
    "\n",
    "move_images_based_on_defect(img_directory, txt_directory, normal_directory, defect_directory)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48fcd7183f39c0c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 최종적으로 평가를 진행할 테스트 데이터셋에 기본적인 전처리를 진행하여 테스트 데이터셋을 로드합니다. test_dir에 검증용 데이터 경로(val)를 입력해주어야 합니다. (val 디렉토리 밑에는 defect와 normal이 있습니다.)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15ca628ec3e527fe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_dir = \"/content/drive/MyDrive/printing/test\"\n",
    "\n",
    "manual_transforms = transforms.Compose([\n",
    "    transforms.Resize((2532, 824)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Loading TEST dataset...\")\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=manual_transforms)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "class_names = test_dataset.classes\n",
    "print(f\"Class names: {class_names}\")\n",
    "print(f\"Loaded {len(test_dataset)} test images.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f159e7cff482df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 모델의 평가를 진행하는 코드입니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afdadfc3a569451"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device, class_names):\n",
    "    model.eval()\n",
    "    true_labels, predicted_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(true_labels, predicted_labels))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, predicted_labels, target_names=class_names))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c5e6b92701bb1f4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 학습에 활용한 TinyVGG 모델 구조와 동일하게 모델 구조를 정의하였습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b97f7243303c132f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TinyVGG(nn.Module):\n",
    "\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units * 127890, out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f77c5eab43eabe7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 학습 과정에서 저장된 최적의 가중치 tinyVGG_weights_T.pkl를 로드하여, 최종 테스트 데이터셋에 대한 평가를 진행합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed28fb4a65011dcd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tinyvgg_model = TinyVGG(input_shape=3, hidden_units=10, output_shape=2)\n",
    "tinyvgg_model.load_state_dict(torch.load(\"/content/drive/MyDrive/models/tinyVGG_weights_T.pkl\", map_location=device))\n",
    "tinyvgg_model = tinyvgg_model.to(device)\n",
    "tinyvgg_model.eval()\n",
    "\n",
    "print(\"Evaluating TinyVGG on TEST dataset...\")\n",
    "evaluate_model(tinyvgg_model, test_dataloader, device, class_names)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcec106cab283417"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
